#!/usr/bin/env python
# -*- coding: UTF-8 -*-
"""=================================================
@PROJECT_NAME: agentic_knowledge_system
@File    : test_translation.py
@Author  : caixiongjiang
@Date    : 2026/1/14 17:35
@Function: 
    æµ‹è¯•æ–‡æœ¬ç¿»è¯‘åŠŸèƒ½
    - ä» mineru è§£æçš„ PDF ç»“æœä¸­æå–æ–‡æœ¬å’Œè¡¨æ ¼
    - ä½¿ç”¨å¤šç§ç›®æ ‡è¯­è¨€è¿›è¡Œç¿»è¯‘æµ‹è¯•
    - ä½¿ç”¨ OpenAI æ ¼å¼è°ƒç”¨æ¨¡å‹
@Modify History:
         
@Copyrightï¼šCopyright(c) 2024-2026. All Rights Reserved
=================================================="""

import sys
import json
from pathlib import Path
from typing import List, Dict, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.client.llm import create_llm_client
from src.prompts.background.translation import (
    language_translation_system_prompt,
    language_translation_user_prompt
)
from loguru import logger


# æ”¯æŒçš„ç›®æ ‡è¯­è¨€åˆ—è¡¨
TARGET_LANGUAGES = [
    {"code": "zh-CN", "name": "Simplified Chinese"},
    {"code": "zh-TW", "name": "Traditional Chinese"},
    # {"code": "en", "name": "English"},
    # {"code": "ru", "name": "Russian"},
    # {"code": "ja", "name": "Japanese"},
    # {"code": "ko", "name": "Korean"},
    # {"code": "fr", "name": "French"},
    # {"code": "de", "name": "German"},
    # {"code": "es", "name": "Spanish"},
    # {"code": "pt", "name": "Portuguese"},
    # {"code": "it", "name": "Italian"},
    # {"code": "pl", "name": "Polish"},
    # {"code": "vi", "name": "Vietnamese"}, 
    # {"code": "hi", "name": "Hindi"},
    # {"code": "es-MX", "name": "Mexican Spanish"}
]


class TranslationTester:
    """ç¿»è¯‘æµ‹è¯•ç±»"""
    
    def __init__(
        self,
        provider: str = "openai",
        model_name: str = "gpt-4o-mini",
        temperature: float = 0.3,
        max_tokens: int = 8000,
        timeout: int = 300
    ):
        """
        åˆå§‹åŒ–ç¿»è¯‘æµ‹è¯•å™¨
        
        Args:
            provider: LLM æä¾›å•†ï¼ˆé»˜è®¤ openaiï¼‰
            model_name: æ¨¡å‹åç§°ï¼ˆé»˜è®¤ gpt-4o-miniï¼‰
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤300ç§’ï¼ˆ5åˆ†é’Ÿï¼‰
        """
        self.provider = provider
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.timeout = timeout
        
        logger.info(
            f"åˆå§‹åŒ–ç¿»è¯‘æµ‹è¯•å™¨ - Provider: {provider}, Model: {model_name}, "
            f"Timeout: {timeout}s"
        )
    
    def load_mineru_result(self, json_path: str) -> List[Dict[str, Any]]:
        """
        åŠ è½½ mineru è§£æç»“æœ
        
        Args:
            json_path: content_list.json æ–‡ä»¶è·¯å¾„
            
        Returns:
            è§£æåçš„å†…å®¹åˆ—è¡¨
        """
        logger.info(f"åŠ è½½ mineru è§£æç»“æœ: {json_path}")
        
        with open(json_path, 'r', encoding='utf-8') as f:
            content_list = json.load(f)
        
        logger.info(f"åŠ è½½å®Œæˆï¼Œå…± {len(content_list)} ä¸ªå…ƒç´ ")
        return content_list
    
    def extract_text_and_tables_by_page(
        self,
        content_list: List[Dict[str, Any]],
        page_limit: Optional[int] = None
    ) -> Dict[int, str]:
        """
        ä» mineru ç»“æœä¸­æŒ‰é¡µæå–æ–‡æœ¬å’Œè¡¨æ ¼å†…å®¹
        
        Args:
            content_list: mineru è§£æçš„å†…å®¹åˆ—è¡¨
            page_limit: é™åˆ¶æå–çš„é¡µæ•°ï¼ˆé»˜è®¤ä¸ºNoneï¼Œè¡¨ç¤ºæå–æ‰€æœ‰é¡µï¼‰
            
        Returns:
            å­—å…¸ï¼Œkeyä¸ºé¡µç ï¼Œvalueä¸ºè¯¥é¡µçš„æ‹¼æ¥æ–‡æœ¬å†…å®¹
        """
        page_info = "æ‰€æœ‰é¡µ" if page_limit is None else f"å‰{page_limit}é¡µ"
        logger.info(f"å¼€å§‹æŒ‰é¡µæå–æ–‡æœ¬å’Œè¡¨æ ¼å†…å®¹ï¼ˆé¡µæ•°é™åˆ¶: {page_info}ï¼‰")
        
        # æŒ‰é¡µç»„ç»‡å†…å®¹
        pages_content = {}
        
        for item in content_list:
            page_idx = item.get("page_idx", 0)
            
            # åªæå–æŒ‡å®šé¡µæ•°çš„å†…å®¹ï¼ˆå¦‚æœpage_limitä¸ºNoneåˆ™æå–æ‰€æœ‰é¡µï¼‰
            if page_limit is not None and page_idx >= page_limit:
                continue
            
            # åˆå§‹åŒ–è¯¥é¡µçš„å†…å®¹åˆ—è¡¨
            if page_idx not in pages_content:
                pages_content[page_idx] = []
            
            item_type = item.get("type")
            
            # æå–æ–‡æœ¬ç±»å‹
            if item_type == "text":
                text = item.get("text", "").strip()
                if text:
                    pages_content[page_idx].append(text)
                    logger.debug(f"é¡µ{page_idx}: æå–æ–‡æœ¬: {text[:50]}...")
            
            # æå–è¡¨æ ¼ç±»å‹
            elif item_type == "table":
                # è¡¨æ ¼æ ‡é¢˜
                table_caption = item.get("table_caption", [])
                if table_caption:
                    caption_text = " ".join(table_caption)
                    pages_content[page_idx].append(f"table_caption: {caption_text}")
                    logger.debug(f"é¡µ{page_idx}: æå–è¡¨æ ¼æ ‡é¢˜: {caption_text[:50]}...")
                
                # è¡¨æ ¼ä¸»ä½“ï¼ˆHTMLæ ¼å¼ï¼‰
                table_body = item.get("table_body", "").strip()
                if table_body:
                    pages_content[page_idx].append(f"table_body: {table_body}")
                    logger.debug(f"é¡µ{page_idx}: æå–è¡¨æ ¼ä¸»ä½“: {table_body[:100]}...")
                
                # è¡¨æ ¼è„šæ³¨
                table_footnote = item.get("table_footnote", [])
                if table_footnote:
                    footnote_text = " ".join(table_footnote)
                    pages_content[page_idx].append(f"table_footnote: {footnote_text}")
                    logger.debug(f"é¡µ{page_idx}: æå–è¡¨æ ¼è„šæ³¨: {footnote_text[:50]}...")
        
        # æ‹¼æ¥æ¯é¡µçš„å†…å®¹
        pages_text = {}
        for page_idx in sorted(pages_content.keys()):
            page_text = "\n\n".join(pages_content[page_idx])
            pages_text[page_idx] = page_text
            logger.info(f"é¡µ{page_idx}: æå–å®Œæˆï¼Œé•¿åº¦: {len(page_text)} å­—ç¬¦")
        
        logger.info(f"æ€»å…±æå– {len(pages_text)} é¡µå†…å®¹")
        return pages_text
    
    def translate_text(
        self,
        text: str,
        target_language_code: str,
        target_language_name: str
    ) -> Dict[str, Any]:
        """
        ç¿»è¯‘æ–‡æœ¬åˆ°ç›®æ ‡è¯­è¨€
        
        Args:
            text: å¾…ç¿»è¯‘çš„æ–‡æœ¬
            target_language_code: ç›®æ ‡è¯­è¨€ä»£ç ï¼ˆå¦‚ zh-CNï¼‰
            target_language_name: ç›®æ ‡è¯­è¨€åç§°ï¼ˆå¦‚ Simplified Chineseï¼‰
            
        Returns:
            ç¿»è¯‘ç»“æœå­—å…¸ï¼ŒåŒ…å«ç¿»è¯‘å†…å®¹ã€tokenä½¿ç”¨ç­‰ä¿¡æ¯
        """
        logger.info(f"å¼€å§‹ç¿»è¯‘åˆ° {target_language_name} ({target_language_code})")
        
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = language_translation_system_prompt.format(
            TARGET_LANGUAGE_CODE=target_language_code,
            TARGET_LANGUAGE_NAME=target_language_name
        )
        
        # æ„å»ºç”¨æˆ·æç¤ºè¯
        user_prompt = language_translation_user_prompt.format(
            input_text=text
        )
        
        # åˆ›å»ºå®¢æˆ·ç«¯å¹¶è¿›è¡Œç¿»è¯‘
        try:
            with create_llm_client(
                provider=self.provider,
                model_name=self.model_name,
                temperature=self.temperature,
                max_tokens=self.max_tokens,
                timeout=self.timeout
            ) as client:
                response = client.generate(
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ]
                )
                
                # æå–ç¿»è¯‘ç»“æœï¼ˆç§»é™¤ä»£ç å—æ ‡è®°ï¼‰
                translated_content = response.content.strip()
                
                # ç§»é™¤ Markdown ä»£ç å—åŒ…è£¹ï¼ˆå¦‚æœæœ‰ï¼‰
                if translated_content.startswith("````"):
                    lines = translated_content.split("\n")
                    # ç§»é™¤ç¬¬ä¸€è¡Œå’Œæœ€åä¸€è¡Œçš„å››ä¸ªåå¼•å·
                    if len(lines) > 2:
                        translated_content = "\n".join(lines[1:-1])
                elif translated_content.startswith("```"):
                    lines = translated_content.split("\n")
                    # ç§»é™¤ç¬¬ä¸€è¡Œå’Œæœ€åä¸€è¡Œçš„ä¸‰ä¸ªåå¼•å·
                    if len(lines) > 2:
                        translated_content = "\n".join(lines[1:-1])
                
                logger.info(
                    f"ç¿»è¯‘å®Œæˆ - Tokenä½¿ç”¨: {response.usage.total_tokens}, "
                    f"ç¿»è¯‘å†…å®¹é•¿åº¦: {len(translated_content)} å­—ç¬¦"
                )
                
                # æ‰“å°ç¿»è¯‘å†…å®¹é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰
                print("\n" + "=" * 80)
                print(f"ç¿»è¯‘è¯­è¨€: {target_language_name} ({target_language_code})")
                print(f"æ¨¡å‹: {response.model}")
                print(f"Tokenä½¿ç”¨: æç¤º={response.usage.prompt_tokens}, "
                      f"å®Œæˆ={response.usage.completion_tokens}, "
                      f"æ€»è®¡={response.usage.total_tokens}")
                print("-" * 80)
                print("ç¿»è¯‘å†…å®¹é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰:")
                print(translated_content[:500])
                if len(translated_content) > 500:
                    print(f"\n... (è¿˜æœ‰ {len(translated_content) - 500} ä¸ªå­—ç¬¦)")
                print("=" * 80 + "\n")
                
                return {
                    "target_language_code": target_language_code,
                    "target_language_name": target_language_name,
                    "translated_content": translated_content,
                    "model": response.model,
                    "tokens_used": response.usage.total_tokens,
                    "prompt_tokens": response.usage.prompt_tokens,
                    "completion_tokens": response.usage.completion_tokens,
                    "finish_reason": response.finish_reason
                }
        
        except Exception as e:
            logger.error(f"ç¿»è¯‘å¤±è´¥: {e}")
            
            # æ‰“å°é”™è¯¯ä¿¡æ¯
            print("\n" + "=" * 80)
            print(f"âŒ ç¿»è¯‘å¤±è´¥: {target_language_name} ({target_language_code})")
            print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
            print("=" * 80 + "\n")
            
            return {
                "target_language_code": target_language_code,
                "target_language_name": target_language_name,
                "error": str(e)
            }
    
    def run_translation_tests(
        self,
        mineru_json_path: str,
        output_dir: str,
        page_limit: Optional[int] = None,
        language_limit: Optional[int] = None
    ):
        """
        è¿è¡Œç¿»è¯‘æµ‹è¯•
        
        Args:
            mineru_json_path: mineru è§£æç»“æœçš„ content_list.json è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            page_limit: é™åˆ¶æå–çš„é¡µæ•°ï¼ˆé»˜è®¤ä¸ºNoneï¼Œè¡¨ç¤ºæå–æ‰€æœ‰é¡µï¼‰
            language_limit: é™åˆ¶æµ‹è¯•çš„è¯­è¨€æ•°é‡ï¼ˆNoneè¡¨ç¤ºæµ‹è¯•æ‰€æœ‰è¯­è¨€ï¼‰
        """
        # æ‰“å°æµ‹è¯•å¼€å§‹ä¿¡æ¯
        print("\n" + "ğŸš€" * 40)
        print("ğŸŒ ç¿»è¯‘æµ‹è¯•å¼€å§‹")
        print(f"ğŸ“Œ æä¾›å•†: {self.provider}")
        print(f"ğŸ¤– æ¨¡å‹: {self.model_name}")
        print(f"â±ï¸  è¶…æ—¶æ—¶é—´: {self.timeout}ç§’")
        print(f"ğŸ¯ æœ€å¤§Token: {self.max_tokens}")
        print(f"ğŸ“„ æºæ–‡ä»¶: {mineru_json_path}")
        print("ğŸš€" * 40 + "\n")
        
        logger.info("=" * 80)
        logger.info("å¼€å§‹ç¿»è¯‘æµ‹è¯•")
        logger.info("=" * 80)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # 1. åŠ è½½ mineru ç»“æœ
        content_list = self.load_mineru_result(mineru_json_path)
        
        # 2. æŒ‰é¡µæå–æ–‡æœ¬å’Œè¡¨æ ¼
        pages_text = self.extract_text_and_tables_by_page(content_list, page_limit)
        
        # ä¿å­˜æ¯é¡µçš„æºæ–‡æœ¬
        for page_idx, page_text in pages_text.items():
            source_file = output_path / f"source_text_page_{page_idx}.txt"
            with open(source_file, 'w', encoding='utf-8') as f:
                f.write(page_text)
            logger.info(f"é¡µ{page_idx}æºæ–‡æœ¬å·²ä¿å­˜: {source_file}")
        
        total_chars = sum(len(text) for text in pages_text.values())
        print(f"ğŸ“ æºæ–‡æœ¬å·²ä¿å­˜: {len(pages_text)} é¡µ")
        print(f"ğŸ“Š æ€»é•¿åº¦: {total_chars} å­—ç¬¦\n")
        
        # 3. å¯¹æ¯ç§è¯­è¨€è¿›è¡Œç¿»è¯‘æµ‹è¯•
        test_languages = TARGET_LANGUAGES[:language_limit] if language_limit else TARGET_LANGUAGES
        print(f"ğŸ¯ å°†æµ‹è¯• {len(test_languages)} ç§è¯­è¨€: {', '.join([lang['code'] for lang in test_languages])}\n")
        
        all_results = []
        
        for i, lang in enumerate(test_languages, 1):
            # æ‰“å°æµ‹è¯•å¼€å§‹ä¿¡æ¯
            print("\n" + "ğŸŒ" * 40)
            print(f"ğŸ“ å¼€å§‹æµ‹è¯• {i}/{len(test_languages)}: {lang['name']} ({lang['code']})")
            print("ğŸŒ" * 40 + "\n")
            
            logger.info(f"\n{'=' * 80}")
            logger.info(f"æµ‹è¯• {i}/{len(test_languages)}: {lang['name']} ({lang['code']})")
            logger.info(f"{'=' * 80}")
            
            # å¯¹æ¯ä¸€é¡µè¿›è¡Œç¿»è¯‘
            page_results = {}
            all_pages_success = True
            
            for page_idx in sorted(pages_text.keys()):
                page_text = pages_text[page_idx]
                
                print(f"\n  ğŸ“„ æ­£åœ¨ç¿»è¯‘ç¬¬ {page_idx} é¡µ ({len(page_text)} å­—ç¬¦)...")
                logger.info(f"ç¿»è¯‘ç¬¬ {page_idx} é¡µåˆ° {lang['name']}")
                
                # ç¿»è¯‘è¯¥é¡µ
                result = self.translate_text(
                    text=page_text,
                    target_language_code=lang["code"],
                    target_language_name=lang["name"]
                )
                
                page_results[page_idx] = result
                
                # ä¿å­˜è¯¥é¡µçš„ç¿»è¯‘ç»“æœ
                if "error" not in result:
                    translation_file = output_path / f"translated_{lang['code']}_page_{page_idx}.txt"
                    with open(translation_file, 'w', encoding='utf-8') as f:
                        f.write(result["translated_content"])
                    logger.info(f"âœ… é¡µ{page_idx}ç¿»è¯‘ç»“æœå·²ä¿å­˜: {translation_file}")
                    print(f"  âœ… é¡µ{page_idx}å·²ä¿å­˜: {translation_file}\n")
                else:
                    all_pages_success = False
                    logger.error(f"âŒ é¡µ{page_idx}ç¿»è¯‘å¤±è´¥: {result['error']}")
            
            # æ±‡æ€»è¯¥è¯­è¨€çš„æ‰€æœ‰é¡µç¿»è¯‘ç»“æœ
            combined_result = {
                "target_language_code": lang["code"],
                "target_language_name": lang["name"],
                "pages": page_results,
                "all_pages_success": all_pages_success,
                "total_tokens": sum(r.get("tokens_used", 0) for r in page_results.values() if "error" not in r)
            }
            
            all_results.append(combined_result)
        
        # 4. ä¿å­˜å®Œæ•´çš„æµ‹è¯•ç»“æœ
        summary_file = output_path / "translation_summary.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump({
                "provider": self.provider,
                "model": self.model_name,
                "temperature": self.temperature,
                "max_tokens": self.max_tokens,
                "total_pages": len(pages_text),
                "total_chars": sum(len(text) for text in pages_text.values()),
                "page_limit": page_limit,
                "test_languages": [lang["code"] for lang in test_languages],
                "results": all_results
            }, f, ensure_ascii=False, indent=2)
        
        # ç»Ÿè®¡ä¿¡æ¯
        success_count = sum(1 for r in all_results if r.get("all_pages_success", False))
        fail_count = len(all_results) - success_count
        total_tokens = sum(r.get("total_tokens", 0) for r in all_results)
        
        # æ‰“å°æµ‹è¯•å®Œæˆä¿¡æ¯
        print("\n" + "ğŸ‰" * 40)
        print("âœ… ç¿»è¯‘æµ‹è¯•å®Œæˆï¼")
        print("=" * 80)
        print("ğŸ“Š æµ‹è¯•ç»Ÿè®¡:")
        print(f"  ğŸ“„ æ€»é¡µæ•°: {len(pages_text)}")
        print(f"  ğŸŒ æµ‹è¯•è¯­è¨€æ•°: {len(all_results)}")
        print(f"  âœ… å…¨éƒ¨æˆåŠŸ: {success_count}/{len(all_results)}")
        print(f"  âŒ éƒ¨åˆ†/å…¨éƒ¨å¤±è´¥: {fail_count}/{len(all_results)}")
        print(f"  ğŸª™ æ€»Tokenä½¿ç”¨: {total_tokens:,}")
        print(f"  ğŸ“ ç»“æœä¿å­˜åœ¨: {output_path}")
        print(f"  ğŸ“„ æµ‹è¯•æ‘˜è¦: {summary_file}")
        print("=" * 80)
        print("ğŸ‰" * 40 + "\n")
        
        logger.info(f"\n{'=' * 80}")
        logger.info(f"ç¿»è¯‘æµ‹è¯•å®Œæˆï¼")
        logger.info(f"ç»“æœä¿å­˜åœ¨: {output_path}")
        logger.info(f"æµ‹è¯•æ‘˜è¦: {summary_file}")
        logger.info(f"{'=' * 80}\n")
        
        logger.info("æµ‹è¯•ç»Ÿè®¡:")
        logger.info(f"  - æ€»é¡µæ•°: {len(pages_text)}")
        logger.info(f"  - æµ‹è¯•è¯­è¨€æ•°: {len(all_results)}")
        logger.info(f"  - å…¨éƒ¨æˆåŠŸ: {success_count}")
        logger.info(f"  - éƒ¨åˆ†/å…¨éƒ¨å¤±è´¥: {fail_count}")
        logger.info(f"  - æ€»Tokenä½¿ç”¨: {total_tokens}")


def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®æ—¥å¿—
    logger.remove()
    logger.add(
        sys.stderr,
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>",
        level="INFO"
    )
    
    # é…ç½®å‚æ•°
    mineru_json_path = project_root / "tmp_results" / "parser" / "mineru" / "content_list.json"
    output_dir = project_root / "tmp_results" / "translation_test"
    
    # åˆ›å»ºç¿»è¯‘æµ‹è¯•å™¨
    tester = TranslationTester(
        provider="openai",  # ä½¿ç”¨ OpenAI
        model_name="ali/qwen3-max",
        temperature=0.3,
        max_tokens=32000,
        timeout=600
    )
    
    # è¿è¡Œç¿»è¯‘æµ‹è¯•
    tester.run_translation_tests(
        mineru_json_path=str(mineru_json_path),
        output_dir=str(output_dir),
        page_limit=None,  # è®¾ç½®ä¸ºNoneå¯æµ‹è¯•æ‰€æœ‰é¡µ
        language_limit=None  # è®¾ç½®ä¸ºNoneå¯æµ‹è¯•æ‰€æœ‰è¯­è¨€
    )


if __name__ == "__main__":
    main()
